# Prepare Datasets for CLIP-VIS

## Structure for dataset:
```
datasets/
  lvis/              # LVIS
  coco/              # COCO
  lvvis/             # LV-VIS
  ovis/              # OVIS
  ytvis19/           # YouTube-VIS2019
  ytvis21/           # YouTube-VIS2021
  burst/             # BURST
```
## Prepare data for [LVIS](https://www.lvisdataset.org/):

### Expected data structure

```
lvis/
  lvis_v1_train.json
  lvis_v1_train_norare.json
  lvis_v1_val.json
```
Download the LVIS dataset annotations from https://www.lvisdataset.org/dataset
```bash
wget https://dl.fbaipublicfiles.com/LVIS/lvis_v1_train.json.zip
wget https://dl.fbaipublicfiles.com/LVIS/lvis_v1_val.json.zip
```
Next, prepare the open-vocabulary LVIS training annotations lvis_v1_train.json using
```bash
python tools/remove_lvis_rare.py --ann datasets/lvis/lvis_v1_train.json
```
## Prepare data for [COCO(2017)](https://cocodataset.org/):

### Expected data structure

```
coco/
  annotations/
    instances_train2017.json
    instances_val2017.json
  train2017/
  val2017/
```
Download the COCO dataset from https://cocodataset.org/#download
```bash
### Images
wget http://images.cocodataset.org/zips/train2017.zip
wget http://images.cocodataset.org/zips/val2017.zip
### Annotations
wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip
```

## Prepare data for [LV-VIS](https://github.com/haochenheheda/LVVIS/):

### Expected data structure 
```
lvvis/
  train/
    JPEGImages/
    train_instances_.json
  val/
    JPEGImages/
    val_instances_.json
  test/
    JPEGImages/
  
```
Download the data of LV-VIS from https://github.com/haochenheheda/LVVIS/ .
```bash
### Videos
wget https://drive.google.com/file/d/1er2lBQLF75TI5O4wzGyur0YYoohMK6C3view?usp=sharing
wget https://drive.google.com/file/d/1vTYUz_XLOBnYb9e7upJsZM-nQz2S6wDn/view?usp=drive_link
### Annotations
wget https://drive.google.com/file/d/1k-o8gBMD7m1-fghw-a1iNDZCi2ZZgV9g/view?usp=sharing
wget https://drive.google.com/file/d/1stPD818M3gv7zUV3UIZG1Suru7Tk54jo/view?usp=sharing
```

## Prepare data for [OVIS](https://songbai.site/ovis/):

### Expected data structure 
```
ovis/
  valid/
  annotations/
    annotations_valid.json
```
Download the data of OVIS from https://songbai.site/ovis/index.html#download

```bash
wget https://drive.google.com/drive/folders/1eE4lLKCbv54E866XBVce_ebh3oXYq99b?usp=sharing
```

## Prepare data for [YouTube-VIS2019/2021](https://youtube-vos.org/dataset/vis/):


### Expected data structure 
```
ytvis2019/
  train/
    JPEGImages/
  valid/
    JPEGImages/
  train.json
  valid.json
ytvis2021/
  train/
    JPEGImages/
  valid/
    JPEGImages/
  train.json
  valid.json
```
Download the data of YouTube-VIS2019 and YouTube-VIS2021 from https://youtube-vos.org/dataset/vis/.

```bash
#### YouTube-VIS2019
wget https://drive.google.com/drive/folders/1VBeVXSf-HfrhyBurtu1xfGn6zQ-ALpjZ?usp=sharing
wget https://drive.google.com/drive/folders/1BWzrCWyPEmBEKm0lOHe5KLuBuQxUSwqz?usp=sharing
#### YouTube-VIS2021
wget https://drive.google.com/drive/folders/12DxR2HWTVjULNwKVMdYAvhOmZ9gBxsX2?usp=sharing
```
## Prepare data for [BURST](https://github.com/Ali2500/BURST-benchmark):


### Expected data structure 
```
burst/
  info/
    class_split.json
  val/
    ArgoVerse/   
    AVA/
    BDD/                          
    Charades/                     
    HACS/                 
    LaSOT/                        
    YFCC100M/                          
    all_classes.json
    b2y_val.json
  
```
Download the data of BURST from https://github.com/Ali2500/BURST-benchmark. 

```bash
### Image sequences(except AVA and HACS videos).
wget https://motchallenge.net/data/1-TAO_TRAIN.zip
wget https://motchallenge.net/data/2-TAO_VAL.zip 
wget https://motchallenge.net/data/3-TAO_TEST.zip 
### Annotations
wget https://omnomnom.vision.rwth-aachen.de/data/BURST/annotations.zip

```
To download the TAO AVA and HACS videos you need to sign in [MOTChallenge](https://motchallenge.net/login/) account. The b2y_val.json is the youtube-vis format annitation files generated by 
```bsah
python tools/burst2ytvis.py --ann datasets/burst/val/all_classes.json --out datasets/burst/val/b2y_val.json
```